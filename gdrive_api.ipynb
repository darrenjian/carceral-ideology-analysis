{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "import urllib\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handbook URL Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbooks = pd.read_csv('./data/handbook_url_search.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(url_segment):\n",
    "    '''\n",
    "    Extracts key-value pairs from a string formatted 'key=value&key=value&...'\n",
    "    Accepts: str\n",
    "    Returns: dict\n",
    "    '''\n",
    "    params = {}\n",
    "    seg_split = url_segment.split('&')\n",
    "    for item in seg_split:\n",
    "        param_split = re.split(r'=', item, re.IGNORECASE)\n",
    "        params[param_split[0]] = param_split[1]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1 = 'usp=sharing'\n",
    "# test2 = 'usp=sharing&start=false&loop=false'\n",
    "\n",
    "# print(get_params(test1))\n",
    "# print(get_params(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_str(str_list):\n",
    "    '''\n",
    "    Returns the longest string in a list of strings\n",
    "    Accepts: list of str\n",
    "    Returns: str\n",
    "    '''\n",
    "    i_max = 0\n",
    "    for i in range(len(str_list)):\n",
    "        if len(str_list[i]) > len(str_list[i_max]):\n",
    "            i_max = i\n",
    "    return str_list[i_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str0 = ['', 'document', 'd', '1qswHw9m_3ZjzgPcL4Ud2cpSCqF0fj9FRieuwDBOYygo', 'edit']\n",
    "# longest_str(str0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(url):\n",
    "    url_segs = {}\n",
    "    params = {}\n",
    "    \n",
    "    m_beg = re.search(r'(\\w+)://([\\w\\-\\.]+)[\\.com|\\.net|\\.org]', url)\n",
    "    if m_beg:\n",
    "        url_segs['domain'] = m_beg.group()\n",
    "    \n",
    "    m_end = re.search(r'[\\?|#].*', url, re.IGNORECASE)\n",
    "    if m_end:\n",
    "        param_list = m_end.group()\n",
    "        if '=' in param_list:\n",
    "            params = get_params(param_list[1:])\n",
    "\n",
    "    if m_beg and m_end:\n",
    "        if 'url' in params.keys():\n",
    "            url_segs['doc_id'] = None\n",
    "        elif 'id' in params.keys():\n",
    "            url_segs['doc_id'] = params['id']\n",
    "        else:\n",
    "            m_mid = re.split(r'/', url[m_beg.span()[1]:m_end.span()[0]])\n",
    "            if len(longest_str(m_mid)) >= 20:\n",
    "                url_segs['doc_id'] = longest_str(m_mid)\n",
    "            else:\n",
    "                url_segs['doc_id'] = None\n",
    "    else:\n",
    "        m_mid = re.split(r'/', url[m_beg.span()[1]:])\n",
    "        if len(longest_str(m_mid)) >= 20:\n",
    "            url_segs['doc_id'] = longest_str(m_mid)\n",
    "        else:\n",
    "            url_segs['doc_id'] = None\n",
    "        \n",
    "    return {**url_segs, **params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url0 = 'https://drive.google.com/drive/folders/18MvvHcv1M3ePoZQXqCXQKwjOiSrsd4hC'\n",
    "# url1 = 'https://drive.google.com/file/d/1kqI5H-NHTc7hwxWG5_cHjOwMYYnc69wS/view'\n",
    "# url2 = 'https://docs.google.com/document/d/1qswHw9m_3ZjzgPcL4Ud2cpSCqF0fj9FRieuwDBOYygo/edit?usp=sharing'\n",
    "# url3 = 'https://docs.google.com/a/fayette.k12.al.us/document/d/146GiYW5gDxRLppGD-Y23Ga-HA3g0wqo6kC-cTVzGWrw/edit?usp=drive_web'\n",
    "# url4 = 'https://docs.google.com/viewerng/viewer?url=https://www.walkercountyschools.com//cms/lib/AL02210233/Centricity/Domain/75/2017-18%2520Handbook.pdf'\n",
    "# url5 = 'https://docs.google.com/document/d/1Nrz_WtoLC010eigdM2s8muvUbGsqGPRSQzp6YNte3JE/edit#heading=h.aze8y9dllu8'\n",
    "\n",
    "# print(parse_url(url0))\n",
    "# print(parse_url(url1))\n",
    "# print(parse_url(url2))\n",
    "# print(parse_url(url3))\n",
    "# print(parse_url(url4))\n",
    "# print(parse_url(url5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_type(url):\n",
    "    url = str(url)\n",
    "    match_drive = re.search(r'\\.google\\.com', url, re.IGNORECASE)\n",
    "    match_pdf = re.search(r'\\.pdf', url, re.IGNORECASE)\n",
    "    match_doc = re.search(r'\\.doc|\\.rtf', url, re.IGNORECASE)\n",
    "    match_web = re.search(r'http', url, re.IGNORECASE)\n",
    "    if match_drive:\n",
    "        return 'gdrive'\n",
    "    elif match_pdf:\n",
    "        return 'pdf'\n",
    "    elif match_doc:\n",
    "        return 'doc'\n",
    "    elif match_web:\n",
    "        return 'web'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hbooks = pd.read_csv('./data/handbook_url_search.csv')\n",
    "# temp = hbooks.sample(100, random_state = 234).reset_index(drop=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp['doc_type'] = temp['handbooks'].progress_apply(lambda x: doc_type(x))\n",
    "# temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.groupby(['doc_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drive_id(url):\n",
    "    '''\n",
    "    Wrapper to extract the Google doc ID from a url\n",
    "    Accepts: dictionary\n",
    "    Returns: str\n",
    "    '''\n",
    "    try:\n",
    "        parsed_url = parse_url(url)\n",
    "        if parsed_url.get('id'):\n",
    "            return parsed_url.get('id')\n",
    "        elif parsed_url.get('pid') == 'sites' and parsed_url.get('srcid'):\n",
    "            return parsed_url.get('srcid')\n",
    "        else:\n",
    "            return parsed_url.get('doc_id')\n",
    "    except Exception as e:\n",
    "        print((url, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_url(url):\n",
    "    '''\n",
    "    Translates an percent-encoded string to HTTP url encoding\n",
    "    Accepts: str\n",
    "    Returns: str\n",
    "    '''\n",
    "    if isinstance(url, str):\n",
    "        return urllib.parse.unquote(url, encoding='utf-8', errors='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Google drive IDs\n",
    "Note: Some schools upload PDFs or Word docs to Google Drive; these do not have IDs. However, their URLs are specified in the handbook url string. The final dataset should have two columns, one for Google Drive ID if present (to pass to Google Drive API in the next step) and another one for the document URL for those Google Drive links without IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbooks['doc_type'] = hbooks['handbooks'].progress_apply(lambda x: doc_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbooks.groupby(['doc_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdocs = hbooks[hbooks['doc_type'] == 'gdrive'].drop(['index'], axis=1).copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get google drive IDs from handbooks created in Google Workspaces\n",
    "gdocs['doc_id'] = gdocs['handbooks'].progress_apply(lambda x: get_drive_id(x))\n",
    "\n",
    "# Extract urls for files uploaded to Google Drive but not created in Google Workspaces\n",
    "gdocs['doc_url'] = gdocs['handbooks'].progress_apply(lambda x: parse_url(x).get('url'))\n",
    "\n",
    "# Fix url encoding\n",
    "gdocs['doc_url'] = gdocs['doc_url'].progress_apply(lambda x: encode_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdocs.to_csv('./data/handbook_google_docs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get handbooks via Google Drive API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Google Drive API python client (Optional)\n",
    "https://developers.google.com/docs/api/quickstart/python\n",
    "\n",
    "Download files\n",
    "https://developers.google.com/drive/api/guides/manage-downloads#python\n",
    "\n",
    "Note: In Google Cloud Console, Google Drive API must be enabled.\n",
    "\n",
    "Install the Python client from the command line\n",
    "```\n",
    "pip3 install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "```\n",
    "\n",
    "Python client documentation\n",
    "https://github.com/googleapis/google-api-python-client/tree/main/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient, httplib2, oauth2client\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    '/home/nb775_georgetown_edu/auth/gcp-gu-ppalab-b168ee778ab5.json')\n",
    "\n",
    "scoped_credentials = credentials.with_scopes(['https://www.googleapis.com/auth/drive.readonly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "test_url = 'https://drive.google.com/file/d/163QosK8EuTWmFFkyl6yAWb6bVfzOBb8I/view?usp=sharing'\n",
    "file_id = get_drive_id(test_url)\n",
    "\n",
    "# file_id = '1qswHw9m_3ZjzgPcL4Ud2cpSCqF0fj9FRieuwDBOYygo'\n",
    "\n",
    "with open('test.pdf', 'wb') as fh:\n",
    "    try:\n",
    "        request = drive_service.files().export_media(fileId=file_id, mimeType='application/pdf')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print( \"Download %d%%.\" % int(status.progress() * 100))\n",
    "    except HttpError:\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print( \"Download %d%%.\" % int(status.progress() * 100))\n",
    "\n",
    "drive_service.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
