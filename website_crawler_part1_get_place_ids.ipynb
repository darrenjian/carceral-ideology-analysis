{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# API access\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "# Progress bar and timing\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMB revisions March 14, 2022: \n",
    "\n",
    "  * Commenting out some sections so we can collect handbooks from all schools rather than just middle and high schools. \n",
    "  * Adding the NCES school ID (NCESSCH) so we have a unique identifier for each school\n",
    "  * Adding school type (SCH_TYPE_TEXT) so we can filter on regular schools\n",
    "  * Removing grade-specific filters\n",
    "  * Importing revised dataset to account for 11 records that had to be manually fixed\n",
    "  * Setting import datatype to str so IDs don't get mangled into integers\n",
    "  * Keeping original column names throughout (eventually they will be matched back with original dataset)\n",
    "  * Writing a function to replace logic that selects website from multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_request(url_list):\n",
    "    '''\n",
    "    Retrieves json-formatted web server responses for a list of urls\n",
    "    Accepts: list of str\n",
    "    Returns: list of dict (json objects)\n",
    "    '''\n",
    "    results = []\n",
    "    session = requests.Session()\n",
    "    for url in tqdm(url_list):\n",
    "        response = session.request('GET', url)\n",
    "        results.append(response.json())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### School-level source data from NCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the list of schools (note: 11 records manually updated due to shifted columns)\n",
    "school = pd.read_csv('./files/ccd_1819_directory_rev.csv', low_memory=False, dtype=str,\n",
    "                    usecols=['STATENAME', 'NCESSCH', 'SCH_NAME', 'LSTREET1', 'LZIP', 'WEBSITE',\n",
    "                            'SCH_TYPE_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Place IDs from Google Place API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key obtained via Google Cloud Console under project gcp-gu-ppalab\n",
    "local_file = '/Users/nb775/auth/brodnax_places_auth.txt'\n",
    "with open(local_file) as txtfile:\n",
    "    my_key = txtfile.read().strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only regular schools\n",
    "school[['NCESSCH', 'SCH_TYPE_TEXT']].groupby(['SCH_TYPE_TEXT']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_id = school[school['SCH_TYPE_TEXT']=='Regular School'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a search term for the Google Maps API\n",
    "g_place = list(place_id['SCH_NAME']+'%20'+place_id['LSTREET1']+'%20'+place_id['LZIP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the spaces in the search term with '%20' in order to make it compatible with the API\n",
    "place = []\n",
    "for term in g_place:\n",
    "    if isinstance(term, str):\n",
    "        no_space = term.replace(' ', '%20')\n",
    "        place.append(no_space)\n",
    "    else:\n",
    "        place.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the urls for the API \n",
    "pid_url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input=\"\n",
    "pid_param = '&inputtype=textquery&fields=place_id&key=' + my_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a unique url for each school in order to feed that into the API\n",
    "pid_api = []\n",
    "for loc in place:\n",
    "    pid_api.append(pid_url + loc + pid_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_list = session_request(pid_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the errors in order to better understand the results\n",
    "pid_results = [len(result.get('candidates')) for result in pid_list]\n",
    "pid_status = [result['status'] for result in pid_list]\n",
    "pid_error = [result.get('error_message') for result in pid_list]\n",
    "pid_responses = pd.DataFrame({'num_results':pid_results, 'status':pid_status, 'error':pid_error})\n",
    "\n",
    "# Export the errors for analysis\n",
    "pid_responses[pid_responses['num_results'] != 1].to_csv('./files/pid_responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract place IDs from results, keeping the same structure as the original dataframe\n",
    "only_pid = []\n",
    "\n",
    "for result in pid_list:\n",
    "    result_list = result.get('candidates')\n",
    "    if len(result_list) == 1:\n",
    "        only_pid.append(result_list[0].get('place_id'))\n",
    "    elif len(result_list) == 2: # If there are 2 place ids for one school I am wrapping the two place_ids in the following format (place_id 1, place_id 2)\n",
    "        only_pid.append((result_list[0].get('place_id'), result_list[1].get('place_id')))\n",
    "    else:\n",
    "        only_pid.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(only_pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the place_id to the original dataframe\n",
    "place_id['g_pid'] = only_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicating the rows with 2 place_ids\n",
    "place_id = place_id.explode('g_pid')\n",
    "\n",
    "# Replacing the nan values in 'g_pid' as 'None'\n",
    "place_id['g_pid'] = place_id['g_pid'].fillna('None')\n",
    "\n",
    "# Resaving the new list of place_ids to only_pid\n",
    "only_pid = list(place_id['g_pid'])\n",
    "\n",
    "# Checking the shape to make sure that only the rows with 2 place_ids got duplicated\n",
    "place_id.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting data for use in Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data - to be used as input for \"website_crawler_google_place_websites.ipynb\"\n",
    "place_id.to_csv('./files/place_ids.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
